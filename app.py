import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import re
import numpy as np
from collections import Counter
from datetime import datetime
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# ============================================================================
# é¡µé¢é…ç½®
# ============================================================================
st.set_page_config(
    page_title="å¤§æ•°æ®å¼€å‘å®ä¹ å²—ä½åˆ†æå¹³å°",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
    <style>
        .main .block-container {padding-top: 1rem; padding-bottom: 1rem;}
        div[data-testid="metric-container"] {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        div[data-testid="metric-container"] label {color: white !important;}
        div[data-testid="metric-container"] [data-testid="stMetricValue"] {color: white !important;}
        h1 {color: #667eea;}
        h2 {color: #764ba2;}
        .stTabs [data-baseweb="tab-list"] {gap: 8px;}
        .stTabs [data-baseweb="tab"] {
            background-color: #f0f2f6;
            border-radius: 5px;
            padding: 10px 20px;
        }
    </style>
""", unsafe_allow_html=True)

# ============================================================================
# æ•°æ®åŠ è½½ä¸æ¸…æ´—å‡½æ•°
# ============================================================================
@st.cache_data
def load_and_clean_data():
    """åŠ è½½å¹¶æ¸…æ´—æ•°æ®"""
    df = None
    
    # å°è¯•å¤šä¸ªå¯èƒ½çš„æ–‡ä»¶è·¯å¾„
    possible_paths = [
        '../Big_data_development_results.csv',  # æœ¬åœ°å¼€å‘ç¯å¢ƒ
        'Big_data_development_results.csv',     # Streamlit Cloud
        './Big_data_development_results.csv'    # å½“å‰ç›®å½•
    ]
    
    # å°è¯•å¤šç§ç¼–ç å’Œè·¯å¾„è¯»å–CSVæ–‡ä»¶
    for file_path in possible_paths:
        for encoding in ['utf-8', 'gbk', 'gb18030', 'utf-8-sig']:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                break
            except FileNotFoundError:
                continue
            except Exception as e:
                continue
        if df is not None:
            break
    
    # å¦‚æœæ‰€æœ‰ç¼–ç å’Œè·¯å¾„éƒ½å¤±è´¥
    if df is None:
        st.error("âŒ æ— æ³•è¯»å–æ•°æ®æ–‡ä»¶ï¼šBig_data_development_results.csv")
        st.info("ğŸ’¡ è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶åœ¨é¡¹ç›®æ ¹ç›®å½•æˆ–ä¸Šçº§ç›®å½•ä¸­")
        return None
    
    expected_cols = ['èŒä½id', 'èŒä½æ ‡é¢˜', 'è–ªèµ„èŒƒå›´', 'å…¬å¸åç§°', 'å·¥ä½œåœ°ç‚¹', 
                     'æ‰€å¤„è¡Œä¸š', 'å­¦å†è¦æ±‚', 'æ¯å‘¨å¤©æ•°', 'å®ä¹ æ—¶é•¿', 'ç¦åˆ©å¾…é‡',
                     'èŒä½æè¿°', 'ç®€å†è¦æ±‚', 'æˆªæ­¢æ—¥æœŸ', 'è¯¦ç»†åœ°å€', 'è¯¦æƒ…é¡µurl']
    
    if len(df.columns) == len(expected_cols):
        df.columns = expected_cols
    
    # è–ªèµ„æ¸…æ´—
    def parse_salary(salary_str):
        try:
            nums = re.findall(r'\d+', str(salary_str))
            if len(nums) >= 2:
                return int(nums[0]), int(nums[1])
            elif len(nums) == 1:
                return int(nums[0]), int(nums[0])
            else:
                return None, None
        except:
            return None, None
    
    df[['æœ€ä½è–ªèµ„', 'æœ€é«˜è–ªèµ„']] = df['è–ªèµ„èŒƒå›´'].apply(lambda x: pd.Series(parse_salary(x)))
    df['å¹³å‡è–ªèµ„'] = (df['æœ€ä½è–ªèµ„'] + df['æœ€é«˜è–ªèµ„']) / 2
    df['å¹³å‡è–ªèµ„'] = df['å¹³å‡è–ªèµ„'].fillna(0).astype(int)
    
    # åŸå¸‚æå–
    df['åŸå¸‚'] = df['å·¥ä½œåœ°ç‚¹'].astype(str).apply(
        lambda x: x.split('-')[0] if '-' in x else x.split('Â·')[0] if 'Â·' in x else x
    )
    
    # æŠ€èƒ½æå–
    TECH_KEYWORDS = ['Hadoop', 'Spark', 'Flink', 'Python', 'Java', 'SQL', 'Kafka', 
                     'Hive', 'HBase', 'Scala', 'ETL', 'MySQL', 'Redis', 'Elasticsearch',
                     'Docker', 'Kubernetes', 'Linux', 'Shell', 'ClickHouse',
                     'æ•°æ®ä»“åº“', 'æ•°æ®æ¹–', 'å®æ—¶è®¡ç®—', 'ç¦»çº¿è®¡ç®—', 'MapReduce', 'HDFS']
    
    def extract_skills(desc):
        if pd.isna(desc):
            return []
        desc_upper = str(desc).upper()
        return [skill for skill in TECH_KEYWORDS if skill.upper() in desc_upper]
    
    df['æŠ€èƒ½æ ‡ç­¾'] = df['èŒä½æè¿°'].apply(extract_skills)
    
    # å­¦å†æ ‡å‡†åŒ–
    def standardize_education(edu):
        edu_str = str(edu).lower()
        if 'åšå£«' in edu_str:
            return 'åšå£«'
        elif 'ç¡•å£«' in edu_str or 'ç ”ç©¶ç”Ÿ' in edu_str:
            return 'ç¡•å£«'
        elif 'æœ¬ç§‘' in edu_str or 'å­¦å£«' in edu_str:
            return 'æœ¬ç§‘'
        elif 'å¤§ä¸“' in edu_str or 'ä¸“ç§‘' in edu_str:
            return 'å¤§ä¸“'
        else:
            return 'ä¸é™'
    
    df['å­¦å†åˆ†ç±»'] = df['å­¦å†è¦æ±‚'].apply(standardize_education)
    
    # å®ä¹ æ—¶é•¿åˆ†ç±»
    def classify_duration(duration):
        duration_str = str(duration)
        if '3' in duration_str and 'æœˆ' in duration_str:
            return '3ä¸ªæœˆ'
        elif '6' in duration_str and 'æœˆ' in duration_str:
            return '6ä¸ªæœˆ'
        elif 'é•¿æœŸ' in duration_str or 'çµæ´»' in duration_str:
            return 'é•¿æœŸå®ä¹ '
        else:
            return 'å…¶ä»–'
    
    df['å®ä¹ æ—¶é•¿åˆ†ç±»'] = df['å®ä¹ æ—¶é•¿'].apply(classify_duration)
    
    # ç¦åˆ©æ ‡ç­¾æå–
    def extract_welfare(welfare_str):
        if pd.isna(welfare_str):
            return []
        tags = re.split(r'[,ï¼Œ;ï¼›ã€\s]+', str(welfare_str))
        return [tag.strip() for tag in tags if tag.strip()]
    
    df['ç¦åˆ©æ ‡ç­¾'] = df['ç¦åˆ©å¾…é‡'].apply(extract_welfare)
    
    # åˆ é™¤æ— æ•ˆæ•°æ®
    df = df[(df['å¹³å‡è–ªèµ„'] > 0) & (df['åŸå¸‚'].notna()) & (df['åŸå¸‚'] != '')]
    
    return df

# åŠ è½½æ•°æ®
with st.spinner('ğŸ”„ æ­£åœ¨åŠ è½½æ•°æ®...'):
    df = load_and_clean_data()

if df is None or df.empty:
    st.stop()

# ============================================================================
# ä¾§è¾¹æ ç­›é€‰å™¨
# ============================================================================
st.sidebar.title("ğŸ” æ•°æ®ç­›é€‰å™¨")
st.sidebar.markdown("---")

# åŸå¸‚ç­›é€‰
st.sidebar.subheader("ğŸ“ å·¥ä½œåŸå¸‚")
all_cities = sorted(df['åŸå¸‚'].unique().tolist())
selected_cities = st.sidebar.multiselect(
    "é€‰æ‹©åŸå¸‚",
    all_cities,
    default=all_cities[:10] if len(all_cities) > 10 else all_cities
)

# è–ªèµ„èŒƒå›´ç­›é€‰
st.sidebar.subheader("ğŸ’° è–ªèµ„èŒƒå›´")
min_sal = int(df['å¹³å‡è–ªèµ„'].min())
max_sal = int(df['å¹³å‡è–ªèµ„'].max())
salary_range = st.sidebar.slider("æ—¥è–ªèŒƒå›´ï¼ˆå…ƒ/å¤©ï¼‰", min_sal, max_sal, (min_sal, max_sal))

# å­¦å†ç­›é€‰
st.sidebar.subheader("ğŸ“ å­¦å†è¦æ±‚")
all_edu = df['å­¦å†åˆ†ç±»'].unique().tolist()
selected_edu = st.sidebar.multiselect("é€‰æ‹©å­¦å†", all_edu, default=all_edu)

# æŠ€èƒ½ç­›é€‰
st.sidebar.subheader("ğŸ’» æŠ€èƒ½è¦æ±‚")
all_skills = []
for skills in df['æŠ€èƒ½æ ‡ç­¾']:
    all_skills.extend(skills)
unique_skills = sorted(list(set(all_skills)))
selected_skills = st.sidebar.multiselect("é€‰æ‹©æŠ€èƒ½ï¼ˆANDé€»è¾‘ï¼‰", unique_skills, default=[])

# å®ä¹ æ—¶é•¿ç­›é€‰
st.sidebar.subheader("â° å®ä¹ æ—¶é•¿")
all_durations = df['å®ä¹ æ—¶é•¿åˆ†ç±»'].unique().tolist()
selected_durations = st.sidebar.multiselect("é€‰æ‹©æ—¶é•¿", all_durations, default=all_durations)

# ç¦åˆ©ç­›é€‰
st.sidebar.subheader("ğŸ ç¦åˆ©å¾…é‡")
all_welfare = []
for welfare in df['ç¦åˆ©æ ‡ç­¾']:
    all_welfare.extend(welfare)
unique_welfare = sorted(list(set(all_welfare)))[:20]
selected_welfare = st.sidebar.multiselect("é€‰æ‹©ç¦åˆ©", unique_welfare, default=[])

st.sidebar.markdown("---")
st.sidebar.info("ğŸ’¡ æç¤ºï¼šæ‰€æœ‰ç­›é€‰æ¡ä»¶ä¸º AND å…³ç³»")

# ============================================================================
# åº”ç”¨ç­›é€‰
# ============================================================================
filtered_df = df.copy()

if selected_cities:
    filtered_df = filtered_df[filtered_df['åŸå¸‚'].isin(selected_cities)]

if selected_edu:
    filtered_df = filtered_df[filtered_df['å­¦å†åˆ†ç±»'].isin(selected_edu)]

if selected_durations:
    filtered_df = filtered_df[filtered_df['å®ä¹ æ—¶é•¿åˆ†ç±»'].isin(selected_durations)]

filtered_df = filtered_df[
    (filtered_df['å¹³å‡è–ªèµ„'] >= salary_range[0]) &
    (filtered_df['å¹³å‡è–ªèµ„'] <= salary_range[1])
]

if selected_skills:
    filtered_df = filtered_df[
        filtered_df['æŠ€èƒ½æ ‡ç­¾'].apply(lambda x: all(skill in x for skill in selected_skills))
    ]

if selected_welfare:
    filtered_df = filtered_df[
        filtered_df['ç¦åˆ©æ ‡ç­¾'].apply(lambda x: any(w in x for w in selected_welfare))
    ]

# ============================================================================
# ä¸»ç•Œé¢
# ============================================================================
st.title("ğŸ“Š å¤§æ•°æ®å¼€å‘å®ä¹ å²—ä½åˆ†æå¹³å°")
st.markdown("### ğŸ¯ å¸®åŠ©å­¦ç”Ÿã€æ±‚èŒè€…ã€é«˜æ ¡å°±ä¸šæŒ‡å¯¼ä¸­å¿ƒã€ä¼ä¸šHRå¿«é€Ÿäº†è§£å¸‚åœºè¶‹åŠ¿")

if filtered_df.empty:
    st.warning("âš ï¸ å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ²¡æœ‰æ•°æ®ï¼Œè¯·è°ƒæ•´ç­›é€‰æ¡ä»¶")
    st.stop()

# KPI æŒ‡æ ‡å¡
col1, col2, col3, col4, col5 = st.columns(5)
with col1:
    st.metric("ğŸ“‹ å²—ä½æ€»æ•°", f"{len(filtered_df)}")
with col2:
    st.metric("ğŸ’° å¹³å‡æ—¥è–ª", f"Â¥{filtered_df['å¹³å‡è–ªèµ„'].mean():.0f}")
with col3:
    st.metric("ğŸ¢ æ‹›è˜ä¼ä¸š", f"{filtered_df['å…¬å¸åç§°'].nunique()}")
with col4:
    st.metric("ğŸŒ† è¦†ç›–åŸå¸‚", f"{filtered_df['åŸå¸‚'].nunique()}")
with col5:
    top_city = filtered_df['åŸå¸‚'].mode()[0] if len(filtered_df) > 0 else "æ— "
    st.metric("ğŸ”¥ æœ€çƒ­åŸå¸‚", top_city)

st.markdown("---")

# Tab å¸ƒå±€
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“Š ç»¼åˆæ¦‚è§ˆ", "ğŸ’° è–ªèµ„åˆ†æ", "ğŸ—ºï¸ åœ°åŸŸåˆ†å¸ƒ", "ğŸ’» æŠ€èƒ½éœ€æ±‚", "ğŸ“‹ å²—ä½åˆ—è¡¨"
])

# Tab 1: ç»¼åˆæ¦‚è§ˆ
with tab1:
    st.subheader("ğŸ“ˆ ç»¼åˆæ•°æ®æ¦‚è§ˆ")
    
    col_a, col_b = st.columns(2)
    
    with col_a:
        st.markdown("#### ğŸ“ å­¦å†è¦æ±‚åˆ†å¸ƒ")
        edu_counts = filtered_df['å­¦å†åˆ†ç±»'].value_counts().reset_index()
        edu_counts.columns = ['å­¦å†', 'æ•°é‡']
        fig_edu = px.pie(edu_counts, values='æ•°é‡', names='å­¦å†', hole=0.4,
                         color_discrete_sequence=px.colors.qualitative.Set3)
        fig_edu.update_traces(textposition='inside', textinfo='percent+label')
        st.plotly_chart(fig_edu, use_container_width=True)
    
    with col_b:
        st.markdown("#### â° å®ä¹ æ—¶é•¿åˆ†å¸ƒ")
        duration_counts = filtered_df['å®ä¹ æ—¶é•¿åˆ†ç±»'].value_counts().reset_index()
        duration_counts.columns = ['æ—¶é•¿', 'æ•°é‡']
        fig_duration = px.bar(duration_counts, x='æ•°é‡', y='æ—¶é•¿', orientation='h',
                             color='æ•°é‡', color_continuous_scale='Viridis', text='æ•°é‡')
        fig_duration.update_layout(showlegend=False)
        st.plotly_chart(fig_duration, use_container_width=True)
    
    st.markdown("---")
    
    col_c, col_d = st.columns(2)
    
    with col_c:
        st.markdown("#### ğŸ¢ å‘å¸ƒå²—ä½æœ€å¤šçš„å…¬å¸ TOP10")
        company_counts = filtered_df['å…¬å¸åç§°'].value_counts().head(10).reset_index()
        company_counts.columns = ['å…¬å¸', 'å²—ä½æ•°']
        fig_company = px.bar(company_counts, x='å²—ä½æ•°', y='å…¬å¸', orientation='h',
                            color='å²—ä½æ•°', color_continuous_scale='Blues', text='å²—ä½æ•°')
        fig_company.update_layout(yaxis={'categoryorder':'total ascending'})
        st.plotly_chart(fig_company, use_container_width=True)
    
    with col_d:
        st.markdown("#### ğŸ­ è¡Œä¸šåˆ†å¸ƒ TOP10")
        industry_counts = filtered_df['æ‰€å¤„è¡Œä¸š'].value_counts().head(10).reset_index()
        industry_counts.columns = ['è¡Œä¸š', 'æ•°é‡']
        fig_industry = px.bar(industry_counts, x='æ•°é‡', y='è¡Œä¸š', orientation='h',
                             color='æ•°é‡', color_continuous_scale='Reds', text='æ•°é‡')
        fig_industry.update_layout(yaxis={'categoryorder':'total ascending'})
        st.plotly_chart(fig_industry, use_container_width=True)

# Tab 2: è–ªèµ„åˆ†æ
with tab2:
    st.subheader("ğŸ’° è–ªèµ„æ·±åº¦åˆ†æ")
    
    col_s1, col_s2 = st.columns(2)
    
    with col_s1:
        st.markdown("#### ğŸ“Š è–ªèµ„åˆ†å¸ƒç›´æ–¹å›¾")
        fig_hist = px.histogram(filtered_df, x='å¹³å‡è–ªèµ„', nbins=40,
                               color_discrete_sequence=['#667eea'],
                               labels={'å¹³å‡è–ªèµ„': 'æ—¥è–ªï¼ˆå…ƒ/å¤©ï¼‰', 'count': 'å²—ä½æ•°é‡'})
        fig_hist.add_vline(x=filtered_df['å¹³å‡è–ªèµ„'].median(), line_dash="dash",
                          line_color="red", annotation_text=f"ä¸­ä½æ•°: Â¥{filtered_df['å¹³å‡è–ªèµ„'].median():.0f}")
        st.plotly_chart(fig_hist, use_container_width=True)
    
    with col_s2:
        st.markdown("#### ğŸ“¦ è–ªèµ„ç®±çº¿å›¾")
        fig_box = px.box(filtered_df, y='å¹³å‡è–ªèµ„', points='all',
                        color_discrete_sequence=['#764ba2'],
                        labels={'å¹³å‡è–ªèµ„': 'æ—¥è–ªï¼ˆå…ƒ/å¤©ï¼‰'})
        st.plotly_chart(fig_box, use_container_width=True)
    
    st.markdown("---")
    
    st.markdown("#### ğŸ“ ä¸åŒå­¦å†è–ªèµ„å¯¹æ¯”")
    fig_edu_salary = px.box(filtered_df, x='å­¦å†åˆ†ç±»', y='å¹³å‡è–ªèµ„', color='å­¦å†åˆ†ç±»',
                            labels={'å¹³å‡è–ªèµ„': 'æ—¥è–ªï¼ˆå…ƒ/å¤©ï¼‰', 'å­¦å†åˆ†ç±»': 'å­¦å†è¦æ±‚'})
    st.plotly_chart(fig_edu_salary, use_container_width=True)
    
    st.markdown("#### ğŸ“‹ è–ªèµ„ç»Ÿè®¡æ‘˜è¦")
    salary_stats = filtered_df['å¹³å‡è–ªèµ„'].describe().to_frame()
    salary_stats.columns = ['ç»Ÿè®¡å€¼']
    salary_stats.index = ['æ•°é‡', 'å¹³å‡å€¼', 'æ ‡å‡†å·®', 'æœ€å°å€¼', '25%åˆ†ä½', 'ä¸­ä½æ•°', '75%åˆ†ä½', 'æœ€å¤§å€¼']
    st.table(salary_stats)

# Tab 3: åœ°åŸŸåˆ†å¸ƒ
with tab3:
    st.subheader("ğŸ—ºï¸ åœ°åŸŸåˆ†å¸ƒåˆ†æ")
    
    col_g1, col_g2 = st.columns(2)
    
    with col_g1:
        st.markdown("#### ğŸ“ åŸå¸‚å²—ä½æ•°é‡ TOP15")
        city_counts = filtered_df['åŸå¸‚'].value_counts().head(15).reset_index()
        city_counts.columns = ['åŸå¸‚', 'å²—ä½æ•°']
        fig_city = px.bar(city_counts, x='åŸå¸‚', y='å²—ä½æ•°', color='å²—ä½æ•°',
                         color_continuous_scale='Teal', text='å²—ä½æ•°')
        st.plotly_chart(fig_city, use_container_width=True)
    
    with col_g2:
        st.markdown("#### ğŸ’° åŸå¸‚å¹³å‡è–ªèµ„ TOP15")
        city_salary = filtered_df.groupby('åŸå¸‚')['å¹³å‡è–ªèµ„'].mean().sort_values(ascending=False).head(15).reset_index()
        city_salary.columns = ['åŸå¸‚', 'å¹³å‡è–ªèµ„']
        fig_city_sal = px.bar(city_salary, x='åŸå¸‚', y='å¹³å‡è–ªèµ„', color='å¹³å‡è–ªèµ„',
                             color_continuous_scale='Oranges', text='å¹³å‡è–ªèµ„')
        fig_city_sal.update_traces(texttemplate='Â¥%{text:.0f}', textposition='outside')
        st.plotly_chart(fig_city_sal, use_container_width=True)
    
    st.markdown("---")
    
    st.markdown("#### ğŸŒ† ä¸»è¦åŸå¸‚è–ªèµ„åˆ†å¸ƒå¯¹æ¯”")
    top_cities = filtered_df['åŸå¸‚'].value_counts().head(10).index
    df_top_cities = filtered_df[filtered_df['åŸå¸‚'].isin(top_cities)]
    fig_city_box = px.box(df_top_cities, x='åŸå¸‚', y='å¹³å‡è–ªèµ„', color='åŸå¸‚',
                          labels={'å¹³å‡è–ªèµ„': 'æ—¥è–ªï¼ˆå…ƒ/å¤©ï¼‰'})
    st.plotly_chart(fig_city_box, use_container_width=True)

# Tab 4: æŠ€èƒ½éœ€æ±‚
with tab4:
    st.subheader("ğŸ’» æŠ€èƒ½éœ€æ±‚åˆ†æ")
    
    all_skills_list = []
    for skills in filtered_df['æŠ€èƒ½æ ‡ç­¾']:
        all_skills_list.extend(skills)
    
    if all_skills_list:
        skill_counter = Counter(all_skills_list)
        
        col_t1, col_t2 = st.columns(2)
        
        with col_t1:
            st.markdown("#### ğŸ“ˆ æŠ€èƒ½éœ€æ±‚æ’è¡Œæ¦œ TOP20")
            skill_df = pd.DataFrame(skill_counter.most_common(20), columns=['æŠ€èƒ½', 'éœ€æ±‚æ¬¡æ•°'])
            fig_skill = px.bar(skill_df, x='éœ€æ±‚æ¬¡æ•°', y='æŠ€èƒ½', orientation='h',
                              color='éœ€æ±‚æ¬¡æ•°', color_continuous_scale='Viridis', text='éœ€æ±‚æ¬¡æ•°')
            fig_skill.update_layout(yaxis={'categoryorder':'total ascending'})
            st.plotly_chart(fig_skill, use_container_width=True)
        
        with col_t2:
            st.markdown("#### â˜ï¸ æŠ€èƒ½è¯äº‘")
            fig_wc, ax = plt.subplots(figsize=(10, 8))
            wordcloud = WordCloud(width=800, height=600, background_color='white',
                                 colormap='viridis', relative_scaling=0.5,
                                 min_font_size=12).generate_from_frequencies(skill_counter)
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis('off')
            st.pyplot(fig_wc)
        
        st.markdown("---")
        
        st.markdown("#### ğŸ”— å¸¸è§æŠ€èƒ½ç»„åˆ TOP10")
        skill_combos = filtered_df['æŠ€èƒ½æ ‡ç­¾'].apply(
            lambda x: ', '.join(sorted(x)) if len(x) > 1 else None
        ).dropna()
        
        if not skill_combos.empty:
            combo_counts = skill_combos.value_counts().head(10).reset_index()
            combo_counts.columns = ['æŠ€èƒ½ç»„åˆ', 'å‡ºç°æ¬¡æ•°']
            st.table(combo_counts)
    else:
        st.info("å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æœªæå–åˆ°æŠ€èƒ½æ ‡ç­¾")

# Tab 5: å²—ä½åˆ—è¡¨
with tab5:
    st.subheader("ğŸ“‹ å²—ä½è¯¦æƒ…åˆ—è¡¨")
    st.info(f"ğŸ“Š å½“å‰ç­›é€‰æ¡ä»¶ä¸‹å…±æœ‰ **{len(filtered_df)}** ä¸ªå²—ä½")
    
    display_df = filtered_df.copy()
    display_df['æŠ€èƒ½'] = display_df['æŠ€èƒ½æ ‡ç­¾'].apply(lambda x: ', '.join(x[:5]) if x else 'æœªæå–')
    display_df['ç¦åˆ©'] = display_df['ç¦åˆ©æ ‡ç­¾'].apply(lambda x: ', '.join(x[:3]) if x else 'æœªæå–')
    
    show_cols = ['èŒä½æ ‡é¢˜', 'å…¬å¸åç§°', 'åŸå¸‚', 'å¹³å‡è–ªèµ„', 'å­¦å†åˆ†ç±»', 
                 'å®ä¹ æ—¶é•¿åˆ†ç±»', 'æŠ€èƒ½', 'ç¦åˆ©', 'è¯¦æƒ…é¡µurl']
    
    # ä½¿ç”¨ st.table æ˜¾ç¤ºï¼ˆæ›´ç¨³å®šï¼‰
    st.dataframe(display_df[show_cols].head(100), use_container_width=True, hide_index=True)
    
    st.markdown("---")
    st.markdown("#### ğŸ“¥ å¯¼å‡ºæ•°æ®")
    
    csv = display_df[show_cols].to_csv(index=False, encoding='utf-8-sig')
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½ç­›é€‰åçš„å²—ä½æ•°æ®ï¼ˆCSVï¼‰",
        data=csv,
        file_name=f"å¤§æ•°æ®å¼€å‘å²—ä½_{datetime.now().strftime('%Y%m%d')}.csv",
        mime="text/csv"
    )

# é¡µè„š
st.markdown("---")
st.markdown("""
    <div style='text-align: center; color: #666;'>
        <p>ğŸ“Š å¤§æ•°æ®å¼€å‘å®ä¹ å²—ä½åˆ†æå¹³å° | æ•°æ®æ¥æºï¼šå®ä¹ åƒ§ | æ›´æ–°æ—¶é—´ï¼š{}</p>
        <p>ğŸ’¡ é€‚ç”¨äºï¼šå­¦ç”Ÿæ±‚èŒã€é«˜æ ¡å°±ä¸šæŒ‡å¯¼ã€ä¼ä¸šHRæ‹›è˜åˆ†æ</p>
    </div>
""".format(datetime.now().strftime('%Y-%m-%d')), unsafe_allow_html=True)
