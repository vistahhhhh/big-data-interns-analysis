"""
å®ä¹ åƒ§å¤§æ•°æ®å¼€å‘å²—ä½æ•°æ®åˆ†æå¹³å°
é¢å‘å­¦ç”Ÿã€æ±‚èŒè€…ã€é«˜æ ¡å°±ä¸šæŒ‡å¯¼ä¸­å¿ƒã€ä¼ä¸šHRçš„äº¤äº’å¼æ•°æ®äº§å“
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import re
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# ==================== é¡µé¢é…ç½® ====================
st.set_page_config(
    page_title="å®ä¹ åƒ§å¤§æ•°æ®å¼€å‘å²—ä½åˆ†æå¹³å°",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== è‡ªå®šä¹‰CSSæ ·å¼ ====================
st.markdown("""
<style>
    /* ä¸»æ ‡é¢˜æ ·å¼ */
    .main-title {
        font-size: 2.5rem;
        font-weight: 700;
        background: linear-gradient(120deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        padding: 1rem 0;
        margin-bottom: 0.5rem;
    }
    
    /* å‰¯æ ‡é¢˜æ ·å¼ */
    .subtitle {
        text-align: center;
        color: #666;
        font-size: 1.1rem;
        margin-bottom: 2rem;
    }
    
    /* æŒ‡æ ‡å¡ç‰‡æ ·å¼ä¼˜åŒ– */
    div[data-testid="metric-container"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.2rem;
        border-radius: 12px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        transition: transform 0.3s ease;
    }
    
    div[data-testid="metric-container"]:hover {
        transform: translateY(-5px);
        box-shadow: 0 8px 12px rgba(0, 0, 0, 0.15);
    }
    
    div[data-testid="metric-container"] label {
        color: white !important;
        font-weight: 600;
        font-size: 0.95rem;
    }
    
    div[data-testid="metric-container"] [data-testid="stMetricValue"] {
        color: white !important;
        font-size: 2rem;
        font-weight: 700;
    }
    
    div[data-testid="metric-container"] [data-testid="stMetricDelta"] {
        color: rgba(255, 255, 255, 0.9) !important;
    }
    
    /* ä¾§è¾¹æ æ ·å¼ */
    section[data-testid="stSidebar"] {
        background: linear-gradient(180deg, #f8f9fa 0%, #e9ecef 100%);
    }
    
    section[data-testid="stSidebar"] > div {
        padding-top: 2rem;
    }
    
    /* æ ‡ç­¾é¡µæ ·å¼ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background-color: #f8f9fa;
        padding: 0.5rem;
        border-radius: 10px;
    }
    
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        border-radius: 8px;
        padding: 0 24px;
        font-weight: 600;
        background-color: white;
        border: 2px solid transparent;
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(120deg, #667eea 0%, #764ba2 100%);
        color: white !important;
        border-color: #667eea;
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .stButton > button {
        background: linear-gradient(120deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.5rem 2rem;
        font-weight: 600;
        transition: all 0.3s ease;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
    }
    
    /* ä¸‹è½½æŒ‰é’®ç‰¹æ®Šæ ·å¼ */
    .stDownloadButton > button {
        background: linear-gradient(120deg, #f093fb 0%, #f5576c 100%);
        color: white;
        border: none;
        border-radius: 8px;
        font-weight: 600;
    }
    
    /* è¾“å…¥æ¡†æ ·å¼ */
    .stTextInput > div > div > input {
        border-radius: 8px;
        border: 2px solid #e9ecef;
        transition: border-color 0.3s ease;
    }
    
    .stTextInput > div > div > input:focus {
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
    
    /* é€‰æ‹©æ¡†æ ·å¼ */
    .stSelectbox > div > div {
        border-radius: 8px;
    }
    
    /* æ»‘å—æ ·å¼ */
    .stSlider > div > div > div {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    }
    
    /* å»é™¤æ»‘å—ä¸‹æ–¹å›ºå®šçš„æœ€å°å€¼å’Œæœ€å¤§å€¼æ ‡ç­¾çš„åº•è‰² */
    .stSlider [data-testid="stTickBar"] > div {
        background: transparent !important;
    }
    
    .stSlider [data-testid="stTickBarMin"],
    .stSlider [data-testid="stTickBarMax"] {
        background: transparent !important;
    }
    
    /* æ•°æ®è¡¨æ ¼æ ·å¼ */
    .dataframe {
        border-radius: 10px;
        overflow: hidden;
    }
    
    /* å›¾è¡¨å®¹å™¨æ ·å¼ */
    .plot-container {
        background: white;
        border-radius: 12px;
        padding: 1rem;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
        margin-bottom: 1.5rem;
    }
    
    /* ä¿¡æ¯æç¤ºæ¡†æ ·å¼ */
    .stAlert {
        border-radius: 10px;
        border-left: 4px solid #667eea;
    }
    
    /* åˆ†éš”çº¿æ ·å¼ */
    hr {
        margin: 2rem 0;
        border: none;
        height: 2px;
        background: linear-gradient(90deg, transparent, #667eea, transparent);
    }
</style>
""", unsafe_allow_html=True)

# ==================== æ•°æ®åŠ è½½ä¸æ¸…æ´— ====================

@st.cache_data
def load_and_clean_data(file_path):
    """åŠ è½½å¹¶æ¸…æ´—æ•°æ®"""
    try:
        df = pd.read_csv(file_path)
        
        # 1. è–ªèµ„æ¸…æ´—
        def extract_avg_salary(salary_str):
            if pd.isna(salary_str):
                return np.nan
            numbers = re.findall(r'\d+', str(salary_str))
            if len(numbers) >= 2:
                return int((int(numbers[0]) + int(numbers[1])) / 2)
            elif len(numbers) == 1:
                return int(numbers[0])
            return np.nan
        
        df['avg_salary'] = df['è–ªèµ„èŒƒå›´'].apply(extract_avg_salary)
        
        # 2. æ¯å‘¨å¤©æ•°æ¸…æ´—
        def clean_days_per_week(days_str):
            if pd.isna(days_str):
                return np.nan
            numbers = re.findall(r'\d+', str(days_str))
            if numbers:
                return f"{numbers[0]}å¤©ï¼å‘¨"
            return days_str
        
        df['æ¯å‘¨å¤©æ•°'] = df['æ¯å‘¨å¤©æ•°'].apply(clean_days_per_week)
        
        # 3. å®ä¹ æ—¶é•¿æ¸…æ´—
        def clean_duration(duration_str):
            if pd.isna(duration_str):
                return np.nan
            numbers = re.findall(r'\d+', str(duration_str))
            if numbers:
                return f"{numbers[0]}ä¸ªæœˆ"
            return duration_str
        
        df['å®ä¹ æ—¶é•¿'] = df['å®ä¹ æ—¶é•¿'].apply(clean_duration)
        
        def extract_duration_months(duration_str):
            if pd.isna(duration_str):
                return np.nan
            numbers = re.findall(r'\d+', str(duration_str))
            if numbers:
                return int(numbers[0])
            return np.nan
        
        df['duration_months'] = df['å®ä¹ æ—¶é•¿'].apply(extract_duration_months)
        
        # 4. å·¥ä½œåœ°ç‚¹æ¸…æ´—
        def extract_city(location_str):
            if pd.isna(location_str):
                return "æœªçŸ¥"
            
            location = str(location_str).strip()
            city_mapping = {
                'åŒ—äº¬': 'åŒ—äº¬', 'åŒ—äº¬å¸‚': 'åŒ—äº¬', 'ä¸Šæµ·': 'ä¸Šæµ·', 'ä¸Šæµ·å¸‚': 'ä¸Šæµ·',
                'æ·±åœ³': 'æ·±åœ³', 'æ·±åœ³å¸‚': 'æ·±åœ³', 'å¹¿å·': 'å¹¿å·', 'å¹¿å·å¸‚': 'å¹¿å·',
                'æ­å·': 'æ­å·', 'æ­å·å¸‚': 'æ­å·', 'æˆéƒ½': 'æˆéƒ½', 'æˆéƒ½å¸‚': 'æˆéƒ½',
                'å—äº¬': 'å—äº¬', 'å—äº¬å¸‚': 'å—äº¬', 'æ­¦æ±‰': 'æ­¦æ±‰', 'æ­¦æ±‰å¸‚': 'æ­¦æ±‰',
                'è¥¿å®‰': 'è¥¿å®‰', 'è¥¿å®‰å¸‚': 'è¥¿å®‰', 'è‹å·': 'è‹å·', 'è‹å·å¸‚': 'è‹å·',
                'é‡åº†': 'é‡åº†', 'é‡åº†å¸‚': 'é‡åº†', 'å¤©æ´¥': 'å¤©æ´¥', 'å¤©æ´¥å¸‚': 'å¤©æ´¥',
            }
            
            if location in city_mapping:
                return city_mapping[location]
            
            for city_key in city_mapping.keys():
                if city_key in location:
                    return city_mapping[city_key]
            
            return location
        
        df['åŸå¸‚'] = df['å·¥ä½œåœ°ç‚¹'].apply(extract_city)
        
        # 5. æŠ€èƒ½æ ‡ç­¾åŒ–
        TECH_SKILLS = ['Java', 'Python', 'SQL', 'Hadoop', 'Spark', 'Flink', 
                       'Hive', 'Kafka', 'Scala', 'C++', 'Linux', 'MySQL', 
                       'Redis', 'HBase', 'Elasticsearch', 'Docker', 'Kubernetes']
        
        def extract_skills(description):
            if pd.isna(description):
                return []
            description_upper = str(description).upper()
            matched = []
            for skill in TECH_SKILLS:
                if skill.upper() in description_upper:
                    matched.append(skill)
            return matched
        
        df['matched_skills'] = df['èŒä½æè¿°'].apply(extract_skills)
        
        # 6. ç¦åˆ©æ ‡ç­¾åŒ–
        def extract_welfare_tags(welfare_str):
            if pd.isna(welfare_str):
                return []
            
            tags = re.split(r'[,ï¼Œã€ï¼›;\s]+', str(welfare_str))
            welfare_mapping = {
                'è½¬æ­£': 'è½¬æ­£æœºä¼š', 'è½¬æ­£æœºä¼š': 'è½¬æ­£æœºä¼š', 'ç•™ç”¨æœºä¼š': 'è½¬æ­£æœºä¼š',
                'æˆ¿è¡¥': 'æˆ¿è¡¥', 'ä½æˆ¿è¡¥è´´': 'æˆ¿è¡¥', 'é¤è¡¥': 'é¤è¡¥', 'é¥­è¡¥': 'é¤è¡¥',
                'ä¸‹åˆèŒ¶': 'ä¸‹åˆèŒ¶', 'é›¶é£Ÿ': 'ä¸‹åˆèŒ¶', 'å‘¨æœ«åŒä¼‘': 'å‘¨æœ«åŒä¼‘',
                'åŒä¼‘': 'å‘¨æœ«åŒä¼‘', 'äº”é™©ä¸€é‡‘': 'äº”é™©ä¸€é‡‘', 'äº”é™©': 'äº”é™©ä¸€é‡‘',
                'äº¤é€šè¡¥åŠ©': 'äº¤é€šè¡¥åŠ©', 'äº¤é€šè¡¥è´´': 'äº¤é€šè¡¥åŠ©', 'èŠ‚æ—¥ç¦åˆ©': 'èŠ‚æ—¥ç¦åˆ©',
                'å¹´ç»ˆå¥–': 'å¹´ç»ˆå¥–', 'å¥–é‡‘': 'å¹´ç»ˆå¥–', 'å¼¹æ€§å·¥ä½œ': 'å¼¹æ€§å·¥ä½œ',
                'å›¢å»º': 'å›¢å»ºæ´»åŠ¨', 'å¸¦è–ªå¹´å‡': 'å¸¦è–ªå¹´å‡', 'å®šæœŸä½“æ£€': 'å®šæœŸä½“æ£€',
            }
            
            standardized_tags = []
            for tag in tags:
                tag = tag.strip()
                if tag and len(tag) > 0:
                    mapped_tag = welfare_mapping.get(tag, tag)
                    if mapped_tag not in standardized_tags:
                        standardized_tags.append(mapped_tag)
            return standardized_tags
        
        # æ£€æŸ¥ç¦åˆ©å¾…é‡åˆ—æ˜¯å¦å­˜åœ¨
        if 'ç¦åˆ©å¾…é‡' in df.columns:
            df['welfare_tags'] = df['ç¦åˆ©å¾…é‡'].apply(extract_welfare_tags)
        else:
            st.warning("âš ï¸ æ•°æ®ä¸­æ²¡æœ‰'ç¦åˆ©å¾…é‡'åˆ—ï¼Œå°†åˆ›å»ºç©ºçš„ç¦åˆ©æ ‡ç­¾")
            df['welfare_tags'] = [[] for _ in range(len(df))]
        
        df['æˆªæ­¢æ—¥æœŸ'] = pd.to_datetime(df['æˆªæ­¢æ—¥æœŸ'], errors='coerce')
        
        return df
    
    except FileNotFoundError:
        st.error(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        st.stop()
    except Exception as e:
        st.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        st.error(f"é”™è¯¯è¯¦æƒ…: {type(e).__name__}")
        import traceback
        st.error(f"å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
        st.stop()


def filter_data(df, cities, education, duration, salary_range, required_skills, welfare_prefs):
    """æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æ¡ä»¶ç­›é€‰æ•°æ®"""
    filtered_df = df.copy()
    
    if cities and len(cities) > 0:
        filtered_df = filtered_df[filtered_df['åŸå¸‚'].isin(cities)]
    
    if education != "å…¨éƒ¨":
        education_hierarchy = {
            'ä¸é™': ['ä¸é™', 'å¤§ä¸“', 'æœ¬ç§‘', 'ç¡•å£«', 'åšå£«'],
            'å¤§ä¸“': ['å¤§ä¸“', 'æœ¬ç§‘', 'ç¡•å£«', 'åšå£«'],
            'æœ¬ç§‘': ['æœ¬ç§‘', 'ç¡•å£«', 'åšå£«'],
            'ç¡•å£«': ['ç¡•å£«', 'åšå£«'],
            'åšå£«': ['åšå£«']
        }
        if education in education_hierarchy:
            filtered_df = filtered_df[filtered_df['å­¦å†è¦æ±‚'].isin(education_hierarchy[education])]
    
    if duration != "å…¨éƒ¨":
        duration_num = int(re.findall(r'\d+', duration)[0])
        filtered_df = filtered_df[filtered_df['duration_months'] >= duration_num]
    
    filtered_df = filtered_df[
        (filtered_df['avg_salary'] >= salary_range[0]) & 
        (filtered_df['avg_salary'] <= salary_range[1])
    ]
    
    if required_skills and len(required_skills) > 0:
        def has_required_skills(skills_list):
            return all(skill in skills_list for skill in required_skills)
        filtered_df = filtered_df[filtered_df['matched_skills'].apply(has_required_skills)]
    
    if welfare_prefs and len(welfare_prefs) > 0:
        # æ£€æŸ¥ welfare_tags åˆ—æ˜¯å¦å­˜åœ¨
        if 'welfare_tags' in filtered_df.columns:
            def has_all_welfare(welfare_list):
                # ç¡®ä¿ welfare_list æ˜¯åˆ—è¡¨ç±»å‹
                if not isinstance(welfare_list, list):
                    return False
                # æ”¹ä¸ºäº¤é›†ï¼šå¿…é¡»åŒ…å«æ‰€æœ‰æŒ‡å®šçš„ç¦åˆ©æ ‡ç­¾
                return all(welfare in welfare_list for welfare in welfare_prefs)
            filtered_df = filtered_df[filtered_df['welfare_tags'].apply(has_all_welfare)]
        else:
            st.warning("âš ï¸ æ•°æ®ä¸­ç¼ºå°‘ç¦åˆ©æ ‡ç­¾ä¿¡æ¯ï¼Œæ— æ³•æŒ‰ç¦åˆ©ç­›é€‰")
    
    return filtered_df


def main():
    # ç¾åŒ–çš„ä¸»æ ‡é¢˜
    st.markdown('<h1 class="main-title">ğŸ“Š å®ä¹ åƒ§å¤§æ•°æ®å¼€å‘å²—ä½åˆ†æå¹³å°</h1>', unsafe_allow_html=True)
    st.markdown('<p class="subtitle">ğŸ¯ æ™ºèƒ½ç­›é€‰ Â· æ•°æ®æ´å¯Ÿ Â· ç²¾å‡†æ¨è</p>', unsafe_allow_html=True)
    st.markdown("---")
    
    DATA_PATH = "Big_data_development_results.csv"
    df = load_and_clean_data(DATA_PATH)
    
    # ä¾§è¾¹æ ç­›é€‰å™¨
    st.sidebar.header("ğŸ” ç­›é€‰æ¡ä»¶")
    
    all_cities = sorted(df['åŸå¸‚'].unique().tolist())
    selected_cities = st.sidebar.multiselect("é€‰æ‹©åŸå¸‚", options=all_cities, default=[])
    
    education_options = ['å…¨éƒ¨', 'ä¸é™', 'å¤§ä¸“', 'æœ¬ç§‘', 'ç¡•å£«', 'åšå£«']
    selected_education = st.sidebar.selectbox("å­¦å†è¦æ±‚", options=education_options, index=0)
    
    duration_options = ['å…¨éƒ¨'] + sorted(df['å®ä¹ æ—¶é•¿'].dropna().unique().tolist())
    selected_duration = st.sidebar.selectbox("æœ€çŸ­å®ä¹ æ—¶é•¿", options=duration_options, index=0)
    
    min_salary = int(df['avg_salary'].min())
    max_salary = int(df['avg_salary'].max())
    salary_range = st.sidebar.slider("æ—¥è–ªèŒƒå›´ï¼ˆå…ƒ/å¤©ï¼‰", min_value=min_salary, max_value=max_salary, 
                                     value=(min_salary, max_salary), step=10)
    
    all_skills = sorted(list(set([skill for skills in df['matched_skills'] for skill in skills])))
    selected_skills = st.sidebar.multiselect("å¿…å¤‡æŠ€èƒ½", options=all_skills, default=[])
    
    # ç¦åˆ©åå¥½ - æ–‡å­—è¾“å…¥æ™ºèƒ½åŒ¹é…ï¼ˆæ”¯æŒå¤šå…³é”®è¯ï¼‰
    selected_welfare = []
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¦åˆ©æ ‡ç­¾æ•°æ®
    if 'welfare_tags' in df.columns:
        try:
            all_welfare = sorted(list(set([tag for tags in df['welfare_tags'] if isinstance(tags, list) for tag in tags])))
        except:
            all_welfare = []
        
        if all_welfare:
            st.sidebar.markdown("---")
            st.sidebar.subheader("ğŸ ç¦åˆ©åå¥½ï¼ˆäº¤é›†åŒ¹é…ï¼‰")
            st.sidebar.caption("ğŸ’¡ è¾“å…¥å¤šä¸ªå…³é”®è¯æ—¶ï¼Œå°†ç­›é€‰åŒæ—¶æ»¡è¶³æ‰€æœ‰æ¡ä»¶çš„å²—ä½")
            
            # æ˜¾ç¤ºç¦åˆ©å¾…é‡ç¤ºä¾‹
            with st.sidebar.expander("ğŸ“‹ å¸¸è§ç¦åˆ©å¾…é‡ç¤ºä¾‹", expanded=False):
                st.write("**è½¬æ­£ç±»ï¼š** è½¬æ­£ã€ç•™ç”¨ã€å¯è½¬æ­£å®ä¹ ")
                st.write("**ä¿é™©ç±»ï¼š** äº”é™©ä¸€é‡‘ã€äº”é™©ã€ç¤¾ä¿")
                st.write("**ä¼‘å‡ç±»ï¼š** å‘¨æœ«åŒä¼‘ã€å¸¦è–ªå¹´å‡ã€å¼¹æ€§å·¥ä½œ")
                st.write("**è¡¥è´´ç±»ï¼š** é¤è¡¥ã€æˆ¿è¡¥ã€äº¤é€šè¡¥åŠ©")
                st.write("**ç¦åˆ©ç±»ï¼š** ä¸‹åˆèŒ¶ã€é›¶é£Ÿæ°´æœã€å¥èº«æˆ¿")
                st.write("**å…¶ä»–ï¼š** èŠ‚æ—¥ç¦åˆ©ã€å¹´ç»ˆå¥–ã€å›¢å»ºæ´»åŠ¨")
            
            # ä½¿ç”¨å¤šä¸ªå•è¡Œè¾“å…¥æ¡†ï¼Œæ›´é€‚åˆæ‰‹æœº
            welfare_input_1 = st.sidebar.text_input(
                "ç¦åˆ©å…³é”®è¯ 1",
                placeholder="ä¾‹å¦‚ï¼šè½¬æ­£",
                key="welfare_1",
                help="è¾“å…¥ç¬¬ä¸€ä¸ªå¿…é¡»æ»¡è¶³çš„ç¦åˆ©å…³é”®è¯"
            )
            welfare_input_2 = st.sidebar.text_input(
                "ç¦åˆ©å…³é”®è¯ 2ï¼ˆå¯é€‰ï¼‰",
                placeholder="ä¾‹å¦‚ï¼šäº”é™©ä¸€é‡‘",
                key="welfare_2",
                help="è¾“å…¥ç¬¬äºŒä¸ªå¿…é¡»æ»¡è¶³çš„ç¦åˆ©å…³é”®è¯ï¼ˆå¯é€‰ï¼‰"
            )
            welfare_input_3 = st.sidebar.text_input(
                "ç¦åˆ©å…³é”®è¯ 3ï¼ˆå¯é€‰ï¼‰",
                placeholder="ä¾‹å¦‚ï¼šåŒä¼‘",
                key="welfare_3",
                help="è¾“å…¥ç¬¬ä¸‰ä¸ªå¿…é¡»æ»¡è¶³çš„ç¦åˆ©å…³é”®è¯ï¼ˆå¯é€‰ï¼‰"
            )
            
            # æ”¶é›†æ‰€æœ‰è¾“å…¥çš„å…³é”®è¯ï¼Œåˆ†ç»„å¤„ç†ï¼ˆæ¯ä¸ªè¾“å…¥æ¡†æ˜¯ä¸€ç»„ï¼‰
            welfare_groups = []
            for inp in [welfare_input_1, welfare_input_2, welfare_input_3]:
                if inp:
                    group_keywords = []
                    # æ”¯æŒç©ºæ ¼åˆ†éš”å¤šä¸ªå…³é”®è¯ï¼ˆåŒä¸€ç»„å†…æ˜¯ORå…³ç³»ï¼‰
                    for kw in inp.split():
                        kw = kw.strip()
                        if kw:
                            group_keywords.append(kw)
                    if group_keywords:
                        welfare_groups.append(group_keywords)
            
            # æ™ºèƒ½åŒ¹é…ç¦åˆ©æ ‡ç­¾ï¼ˆäº¤é›†ï¼‰
            if welfare_groups:
                # ä¸ºæ¯ç»„å…³é”®è¯åŒ¹é…ç¦åˆ©æ ‡ç­¾
                matched_groups = []
                for group in welfare_groups:
                    group_matches = []
                    for keyword in group:
                        for welfare in all_welfare:
                            if keyword.lower() in welfare.lower() or welfare.lower() in keyword.lower():
                                if welfare not in group_matches:
                                    group_matches.append(welfare)
                    matched_groups.append(group_matches)
                
                # æ˜¾ç¤ºæ¯ç»„çš„åŒ¹é…ç»“æœ
                all_matched = []
                for i, matches in enumerate(matched_groups):
                    all_matched.extend(matches)
                    st.sidebar.info(f"å…³é”®è¯ {i+1} åŒ¹é…: {', '.join(matches) if matches else 'æ— '}")
                
                # å°†æ‰€æœ‰åŒ¹é…çš„ç¦åˆ©æ·»åŠ åˆ°selected_welfareï¼ˆç”¨äºäº¤é›†ç­›é€‰ï¼‰
                selected_welfare = list(set(all_matched))
                
                if selected_welfare:
                    st.sidebar.success(f"âœ… å…±åŒ¹é…åˆ° {len(selected_welfare)} ä¸ªç¦åˆ©æ ‡ç­¾")
                    st.sidebar.warning("âš ï¸ ç­›é€‰æ¨¡å¼ï¼šå¿…é¡»åŒæ—¶æ»¡è¶³æ‰€æœ‰è¾“å…¥çš„å…³é”®è¯")
                else:
                    st.sidebar.warning("âš ï¸ æœªåŒ¹é…åˆ°ç›¸å…³ç¦åˆ©")
                    with st.sidebar.expander("ğŸ’¡ å¯ç”¨ç¦åˆ©ç¤ºä¾‹"):
                        for welfare in all_welfare[:10]:
                            st.write(f"â€¢ {welfare}")
        else:
            st.sidebar.info("â„¹ï¸ å½“å‰æ•°æ®ä¸­æ²¡æœ‰ç¦åˆ©æ ‡ç­¾ä¿¡æ¯")
    else:
        st.sidebar.info("â„¹ï¸ æ•°æ®ä¸­ç¼ºå°‘ç¦åˆ©æ ‡ç­¾åˆ—")
    
    filtered_df = filter_data(df, selected_cities, selected_education, selected_duration, 
                             salary_range, selected_skills, selected_welfare)
    
    # æ£€æŸ¥ç­›é€‰åæ˜¯å¦æœ‰æ•°æ®
    if len(filtered_df) == 0:
        st.header("ğŸ“ˆ æ ¸å¿ƒæŒ‡æ ‡")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("å²—ä½æ€»æ•°", "0", delta="å æ¯” 0.0%")
        with col2:
            st.metric("å¹³å‡æ—¥è–ª", "Â¥0", delta="æš‚æ— æ•°æ®")
        with col3:
            st.metric("è¦†ç›–åŸå¸‚", "0", delta=f"æ€»è®¡ {df['åŸå¸‚'].nunique()} ä¸ª")
        with col4:
            st.metric("æ‹›è˜ä¼ä¸š", "0", delta=f"æ€»è®¡ {df['å…¬å¸åç§°'].nunique()} å®¶")
        
        st.markdown("---")
        
        # æ˜¾ç¤ºå‹å¥½çš„æç¤ºä¿¡æ¯
        st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆç­›é€‰æ¡ä»¶çš„ç›®æ ‡å²—ä½")
        st.info("""
        **å»ºè®®ï¼š**
        - ğŸ” å°è¯•æ”¾å®½ç­›é€‰æ¡ä»¶ï¼ˆå¦‚æ‰©å¤§è–ªèµ„èŒƒå›´ã€é€‰æ‹©æ›´å¤šåŸå¸‚ï¼‰
        - ğŸ“š å‡å°‘å¿…å¤‡æŠ€èƒ½çš„æ•°é‡è¦æ±‚
        - ğŸ“ è°ƒæ•´å­¦å†æˆ–å®ä¹ æ—¶é•¿è¦æ±‚
        - ğŸ å‡å°‘ç¦åˆ©åå¥½çš„é™åˆ¶
        """)
        
        # æ˜¾ç¤ºå½“å‰ç­›é€‰æ¡ä»¶
        st.subheader("å½“å‰ç­›é€‰æ¡ä»¶ï¼š")
        filter_info = []
        if selected_cities:
            filter_info.append(f"- **åŸå¸‚**: {', '.join(selected_cities)}")
        if selected_education != "å…¨éƒ¨":
            filter_info.append(f"- **å­¦å†**: {selected_education}")
        if selected_duration != "å…¨éƒ¨":
            filter_info.append(f"- **å®ä¹ æ—¶é•¿**: {selected_duration}")
        filter_info.append(f"- **è–ªèµ„èŒƒå›´**: Â¥{salary_range[0]} - Â¥{salary_range[1]}/å¤©")
        if selected_skills:
            filter_info.append(f"- **å¿…å¤‡æŠ€èƒ½**: {', '.join(selected_skills)}")
        if selected_welfare:
            filter_info.append(f"- **ç¦åˆ©åå¥½**: {', '.join(selected_welfare)}")
        
        st.markdown('\n'.join(filter_info))
        return
    
    # KPI æŒ‡æ ‡å¡ï¼ˆæœ‰æ•°æ®æ—¶ï¼‰- ç¾åŒ–ç‰ˆ
    st.markdown("### ğŸ“ˆ æ ¸å¿ƒæŒ‡æ ‡")
    st.markdown("")  # æ·»åŠ é—´è·
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("å²—ä½æ€»æ•°", f"{len(filtered_df):,}", delta=f"å æ¯” {len(filtered_df)/len(df)*100:.1f}%")
    with col2:
        avg_sal = filtered_df['avg_salary'].mean()
        st.metric("å¹³å‡æ—¥è–ª", f"Â¥{avg_sal:.0f}", delta=f"ä¸­ä½æ•° Â¥{filtered_df['avg_salary'].median():.0f}")
    with col3:
        st.metric("è¦†ç›–åŸå¸‚", f"{filtered_df['åŸå¸‚'].nunique()}", delta=f"æ€»è®¡ {df['åŸå¸‚'].nunique()} ä¸ª")
    with col4:
        st.metric("æ‹›è˜ä¼ä¸š", f"{filtered_df['å…¬å¸åç§°'].nunique()}", delta=f"æ€»è®¡ {df['å…¬å¸åç§°'].nunique()} å®¶")
    
    st.markdown("---")
    
    # ==================== åˆ›å»ºåˆ†é¡µæ ‡ç­¾ ====================
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ’° è–ªèµ„ä¸åŸå¸‚åˆ†æ", 
        "ğŸ› ï¸ æŠ€èƒ½ä¸å­¦å†åˆ†æ", 
        "ğŸ¢ ä¼ä¸šä¸å²—ä½æ¨è",
        "ğŸ­ è¡Œä¸šä¸è¶‹åŠ¿åˆ†æ",
        "ğŸ“‹ æ•°æ®è¯¦æƒ…è¡¨"
    ])
    
    # ==================== ç¬¬1é¡µï¼šè–ªèµ„ä¸åŸå¸‚åˆ†æ ====================
    with tab1:
        st.header("ğŸ’° è–ªèµ„åˆ†å¸ƒåˆ†æ")
        col1, col2 = st.columns(2)
        
        with col1:
            fig_box = go.Figure()
            fig_box.add_trace(go.Box(y=filtered_df['avg_salary'], name='æ—¥è–ªåˆ†å¸ƒ', 
                                     marker_color='#667eea', boxmean='sd',
                                     line=dict(color='#764ba2', width=2)))
            fig_box.update_layout(
                title=dict(text="è–ªèµ„ç®±çº¿å›¾", font=dict(size=18, color='#2c3e50')),
                yaxis_title="æ—¥è–ªï¼ˆå…ƒ/å¤©ï¼‰", 
                height=400,
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)'
            )
            st.plotly_chart(fig_box, use_container_width=True)
        
        with col2:
            fig_hist = px.histogram(filtered_df, x='avg_salary', nbins=30, title="è–ªèµ„åˆ†å¸ƒç›´æ–¹å›¾",
                                   labels={'avg_salary': 'æ—¥è–ªï¼ˆå…ƒ/å¤©ï¼‰'},
                                   color_discrete_sequence=['#667eea'])
            fig_hist.update_layout(
                height=400,
                title=dict(font=dict(size=18, color='#2c3e50')),
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)'
            )
            st.plotly_chart(fig_hist, use_container_width=True)
        
        st.markdown("---")
        
        st.header("ğŸŒ åŸå¸‚å²—ä½çƒ­åŠ›åˆ†æ")
        city_stats = filtered_df.groupby('åŸå¸‚').agg({'èŒä½id': 'count', 'avg_salary': 'mean'}).reset_index()
        city_stats.columns = ['åŸå¸‚', 'å²—ä½æ•°é‡', 'å¹³å‡è–ªèµ„']
        city_stats = city_stats.sort_values('å²—ä½æ•°é‡', ascending=False).head(20)
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig_city_count = px.bar(city_stats, x='åŸå¸‚', y='å²—ä½æ•°é‡', title="å„åŸå¸‚å²—ä½æ•°é‡ TOP20",
                                    color='å²—ä½æ•°é‡', 
                                    color_continuous_scale=[[0, '#667eea'], [1, '#764ba2']])
            fig_city_count.update_layout(
                height=400,
                title=dict(font=dict(size=18, color='#2c3e50')),
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)'
            )
            st.plotly_chart(fig_city_count, use_container_width=True)
        
        with col2:
            fig_city_salary = px.bar(city_stats, x='åŸå¸‚', y='å¹³å‡è–ªèµ„', title="å„åŸå¸‚å¹³å‡è–ªèµ„ TOP20",
                                     color='å¹³å‡è–ªèµ„', 
                                     color_continuous_scale=[[0, '#f093fb'], [1, '#f5576c']])
            fig_city_salary.update_layout(
                height=400,
                title=dict(font=dict(size=18, color='#2c3e50')),
                plot_bgcolor='rgba(0,0,0,0)',
                paper_bgcolor='rgba(0,0,0,0)'
            )
            st.plotly_chart(fig_city_salary, use_container_width=True)
    
    # ==================== ç¬¬2é¡µï¼šæŠ€èƒ½ä¸å­¦å†åˆ†æ ====================
    with tab2:
        st.header("ğŸ› ï¸ æŠ€èƒ½éœ€æ±‚åˆ†æ")
        all_skills_list = [skill for skills in filtered_df['matched_skills'] for skill in skills]
        skill_counter = Counter(all_skills_list)
        skill_df = pd.DataFrame(skill_counter.most_common(20), columns=['æŠ€èƒ½', 'å‡ºç°æ¬¡æ•°'])
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig_skills = px.bar(skill_df, x='å‡ºç°æ¬¡æ•°', y='æŠ€èƒ½', orientation='h', title="é«˜é¢‘æŠ€èƒ½ TOP20",
                               color='å‡ºç°æ¬¡æ•°', color_continuous_scale='Viridis')
            fig_skills.update_layout(height=500, yaxis={'categoryorder': 'total ascending'})
            st.plotly_chart(fig_skills, use_container_width=True)
        
        with col2:
            if len(skill_df) > 0:
                fig_wordcloud = px.scatter(skill_df, x=np.random.randn(len(skill_df)), 
                                          y=np.random.randn(len(skill_df)), size='å‡ºç°æ¬¡æ•°', text='æŠ€èƒ½',
                                          title="æŠ€èƒ½è¯äº‘", color='å‡ºç°æ¬¡æ•°', size_max=60)
                fig_wordcloud.update_traces(textposition='middle center')
                fig_wordcloud.update_layout(height=500, xaxis={'visible': False}, yaxis={'visible': False})
                st.plotly_chart(fig_wordcloud, use_container_width=True)
        
        st.markdown("---")
        
        st.header("ğŸ“ å­¦å†è¦æ±‚åˆ†å¸ƒ")
        education_stats = filtered_df['å­¦å†è¦æ±‚'].value_counts().reset_index()
        education_stats.columns = ['å­¦å†', 'æ•°é‡']
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig_edu_pie = px.pie(education_stats, values='æ•°é‡', names='å­¦å†', title="å­¦å†è¦æ±‚å æ¯”", hole=0.4)
            fig_edu_pie.update_layout(height=400)
            st.plotly_chart(fig_edu_pie, use_container_width=True)
        
        with col2:
            fig_edu_bar = px.bar(education_stats, x='å­¦å†', y='æ•°é‡', title="å­¦å†è¦æ±‚æ•°é‡åˆ†å¸ƒ", color='æ•°é‡')
            fig_edu_bar.update_layout(height=400)
            st.plotly_chart(fig_edu_bar, use_container_width=True)
    
    # ==================== ç¬¬3é¡µï¼šä¼ä¸šä¸å²—ä½æ¨è ====================
    with tab3:
        st.header("ğŸ¢ çƒ­é—¨æ‹›è˜ä¼ä¸š TOP10")
        company_stats = filtered_df['å…¬å¸åç§°'].value_counts().head(10).reset_index()
        company_stats.columns = ['å…¬å¸', 'å²—ä½æ•°é‡']
        
        fig_company = px.bar(company_stats, x='å²—ä½æ•°é‡', y='å…¬å¸', orientation='h', 
                            title="å‘å¸ƒå²—ä½æœ€å¤šçš„å…¬å¸ TOP10", color='å²—ä½æ•°é‡')
        fig_company.update_layout(height=400, yaxis={'categoryorder': 'total ascending'})
        st.plotly_chart(fig_company, use_container_width=True)
        
        st.markdown("---")
        
        st.header("ğŸ’¼ æ¨èå²—ä½ TOP10")
        st.markdown("**æ ¹æ®è–ªèµ„ã€æŠ€èƒ½åŒ¹é…åº¦å’Œç¦åˆ©ç»¼åˆæ¨è**")
        
        # è®¡ç®—æ¨èåˆ†æ•°ï¼šè–ªèµ„æƒé‡50%ï¼ŒæŠ€èƒ½æ•°é‡æƒé‡30%ï¼Œç¦åˆ©æ•°é‡æƒé‡20%
        recommend_df = filtered_df.copy()
        recommend_df['æŠ€èƒ½æ•°é‡'] = recommend_df['matched_skills'].apply(len)
        recommend_df['ç¦åˆ©æ•°é‡'] = recommend_df['welfare_tags'].apply(len)
        
        # å½’ä¸€åŒ–å¤„ç†
        if recommend_df['avg_salary'].max() > 0:
            recommend_df['è–ªèµ„å¾—åˆ†'] = recommend_df['avg_salary'] / recommend_df['avg_salary'].max() * 50
        else:
            recommend_df['è–ªèµ„å¾—åˆ†'] = 0
            
        if recommend_df['æŠ€èƒ½æ•°é‡'].max() > 0:
            recommend_df['æŠ€èƒ½å¾—åˆ†'] = recommend_df['æŠ€èƒ½æ•°é‡'] / recommend_df['æŠ€èƒ½æ•°é‡'].max() * 30
        else:
            recommend_df['æŠ€èƒ½å¾—åˆ†'] = 0
            
        if recommend_df['ç¦åˆ©æ•°é‡'].max() > 0:
            recommend_df['ç¦åˆ©å¾—åˆ†'] = recommend_df['ç¦åˆ©æ•°é‡'] / recommend_df['ç¦åˆ©æ•°é‡'].max() * 20
        else:
            recommend_df['ç¦åˆ©å¾—åˆ†'] = 0
        
        recommend_df['æ¨èåˆ†æ•°'] = recommend_df['è–ªèµ„å¾—åˆ†'] + recommend_df['æŠ€èƒ½å¾—åˆ†'] + recommend_df['ç¦åˆ©å¾—åˆ†']
        
        # æŒ‰æ¨èåˆ†æ•°æ’åºï¼Œå–å‰10
        top_jobs = recommend_df.nlargest(10, 'æ¨èåˆ†æ•°')[[
            'èŒä½æ ‡é¢˜', 'å…¬å¸åç§°', 'avg_salary', 'åŸå¸‚', 'å­¦å†è¦æ±‚', 'å®ä¹ æ—¶é•¿',
            'matched_skills', 'welfare_tags', 'æ¨èåˆ†æ•°', 'è¯¦æƒ…é¡µurl'
        ]].copy()
        
        # æ˜¾ç¤ºæ¨èå²—ä½å¡ç‰‡
        for idx, row in top_jobs.iterrows():
            with st.expander(f"â­ {row['èŒä½æ ‡é¢˜']} - {row['å…¬å¸åç§°']} (æ¨èåˆ†æ•°: {row['æ¨èåˆ†æ•°']:.1f})"):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown(f"**ğŸ’° æ—¥è–ª**: Â¥{row['avg_salary']:.0f}/å¤©")
                    st.markdown(f"**ğŸ“ åŸå¸‚**: {row['åŸå¸‚']}")
                    st.markdown(f"**ğŸ“ å­¦å†**: {row['å­¦å†è¦æ±‚']}")
                    st.markdown(f"**â±ï¸ æ—¶é•¿**: {row['å®ä¹ æ—¶é•¿']}")
                
                with col2:
                    skills_str = ', '.join(row['matched_skills']) if row['matched_skills'] else 'æœªæ ‡æ³¨'
                    st.markdown(f"**ğŸ› ï¸ æŠ€èƒ½è¦æ±‚**: {skills_str}")
                    
                    welfare_str = ', '.join(row['welfare_tags']) if row['welfare_tags'] else 'æœªæ ‡æ³¨'
                    st.markdown(f"**ğŸ ç¦åˆ©å¾…é‡**: {welfare_str}")
                
                st.markdown(f"**ğŸ”— [æŸ¥çœ‹è¯¦æƒ…]({row['è¯¦æƒ…é¡µurl']})**")
    
    # ==================== ç¬¬4é¡µï¼šè¡Œä¸šä¸è¶‹åŠ¿åˆ†æ ====================
    with tab4:
        st.header("ğŸ“… å²—ä½å‘å¸ƒæ—¶é—´è¶‹åŠ¿")
        filtered_df_with_date = filtered_df[filtered_df['æˆªæ­¢æ—¥æœŸ'].notna()].copy()
        
        if len(filtered_df_with_date) > 0:
            filtered_df_with_date['æœˆä»½'] = filtered_df_with_date['æˆªæ­¢æ—¥æœŸ'].dt.to_period('M').astype(str)
            time_stats = filtered_df_with_date.groupby('æœˆä»½').size().reset_index(name='å²—ä½æ•°é‡')
            time_stats = time_stats.sort_values('æœˆä»½')
            
            fig_time = px.line(time_stats, x='æœˆä»½', y='å²—ä½æ•°é‡', title="è¿‘ä¸€å¹´å²—ä½å‘å¸ƒè¶‹åŠ¿", markers=True)
            fig_time.update_layout(height=400)
            st.plotly_chart(fig_time, use_container_width=True)
        else:
            st.info("æš‚æ— æœ‰æ•ˆçš„æ—¶é—´æ•°æ®")
        
        st.markdown("---")
        
        st.header("ğŸ­ è¡Œä¸šåˆ†å¸ƒåˆ†æ")
        industry_stats = filtered_df['æ‰€å¤„è¡Œä¸š'].value_counts().head(15).reset_index()
        industry_stats.columns = ['è¡Œä¸š', 'æ•°é‡']
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig_sunburst = px.sunburst(industry_stats, path=['è¡Œä¸š'], values='æ•°é‡', 
                                       title="è¡Œä¸šåˆ†å¸ƒæ—­æ—¥å›¾", color='æ•°é‡')
            fig_sunburst.update_layout(height=500)
            st.plotly_chart(fig_sunburst, use_container_width=True)
        
        with col2:
            fig_treemap = px.treemap(industry_stats, path=['è¡Œä¸š'], values='æ•°é‡', 
                                    title="è¡Œä¸šåˆ†å¸ƒæ ‘çŠ¶å›¾", color='æ•°é‡')
            fig_treemap.update_layout(height=500)
            st.plotly_chart(fig_treemap, use_container_width=True)
    
    # ==================== ç¬¬5é¡µï¼šæ•°æ®è¯¦æƒ…è¡¨ ====================
    with tab5:
        st.header("ğŸ“‹ å²—ä½è¯¦æƒ…æ•°æ®è¡¨")
        st.markdown(f"**å…± {len(filtered_df)} æ¡å²—ä½ä¿¡æ¯**")
        
        # å‡†å¤‡æ˜¾ç¤ºæ•°æ®
        display_df = filtered_df[['èŒä½æ ‡é¢˜', 'å…¬å¸åç§°', 'avg_salary', 'åŸå¸‚', 'å­¦å†è¦æ±‚', 
                                  'å®ä¹ æ—¶é•¿', 'matched_skills', 'welfare_tags', 'è¯¦æƒ…é¡µurl']].copy()
        display_df.columns = ['èŒä½æ ‡é¢˜', 'å…¬å¸', 'æ—¥è–ª(å…ƒ)', 'åŸå¸‚', 'å­¦å†', 'å®ä¹ æ—¶é•¿', 'æŠ€èƒ½è¦æ±‚', 'ç¦åˆ©', 'è¯¦æƒ…é¡µ']
        
        # å¤„ç†åˆ—è¡¨ç±»å‹çš„åˆ—
        display_df['æŠ€èƒ½è¦æ±‚'] = display_df['æŠ€èƒ½è¦æ±‚'].apply(lambda x: ', '.join(x) if isinstance(x, list) and len(x) > 0 else 'æœªæ ‡æ³¨')
        display_df['ç¦åˆ©'] = display_df['ç¦åˆ©'].apply(lambda x: ', '.join(x) if isinstance(x, list) and len(x) > 0 else 'æœªæ ‡æ³¨')
        
        # é‡ç½®ç´¢å¼•
        display_df = display_df.reset_index(drop=True)
        
        # æ·»åŠ åˆ†é¡µåŠŸèƒ½
        st.markdown("---")
        
        # æ¯é¡µæ˜¾ç¤ºçš„è¡Œæ•°
        rows_per_page = st.selectbox("æ¯é¡µæ˜¾ç¤ºè¡Œæ•°", [10, 25, 50, 100, 200], index=2)
        
        # è®¡ç®—æ€»é¡µæ•°
        total_pages = (len(display_df) - 1) // rows_per_page + 1
        
        # é¡µç é€‰æ‹©
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            page_number = st.number_input(
                f"é¡µç  (å…± {total_pages} é¡µ)", 
                min_value=1, 
                max_value=total_pages, 
                value=1,
                step=1
            )
        
        # è®¡ç®—å½“å‰é¡µçš„æ•°æ®èŒƒå›´
        start_idx = (page_number - 1) * rows_per_page
        end_idx = min(start_idx + rows_per_page, len(display_df))
        
        # æ˜¾ç¤ºå½“å‰é¡µçš„æ•°æ®
        st.markdown(f"**æ˜¾ç¤ºç¬¬ {start_idx + 1} - {end_idx} æ¡ï¼Œå…± {len(display_df)} æ¡**")
        
        # ä½¿ç”¨st.data_editoræ˜¾ç¤ºæ•°æ®ï¼ˆå¯ç¼–è¾‘è¡¨æ ¼ï¼Œæ›´ç¨³å®šï¼‰
        st.data_editor(
            display_df.iloc[start_idx:end_idx],
            use_container_width=True,
            num_rows="fixed",
            disabled=True,
            hide_index=False
        )
        
        st.markdown("---")
        
        # å¯¼å‡ºåŠŸèƒ½
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            csv = display_df.to_csv(index=False, encoding='utf-8-sig')
            st.download_button(
                label="ğŸ“¥ å¯¼å‡ºå…¨éƒ¨æ•°æ®ä¸ºCSV",
                data=csv,
                file_name="filtered_jobs.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        with col2:
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            st.metric("æ•°æ®æ€»è¡Œæ•°", len(display_df))


if __name__ == "__main__":
    main()
